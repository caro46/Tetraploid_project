## [Allpaths](http://software.broadinstitute.org/allpaths-lg/blog/), de novo assembly (possibility of adding a Reference)
STUCTURE: `REFERENCE/DATA/RUN/ASSEMBLIES/SUBDIR`.

INPUTS: sequenced reads, their quality scores and information concerning their pairing (`.fastb` + `.qualb` obtained with `PrepareAllPathsInputs.pl`) + ploidy files (only `1=haploid`, `2=diploid`).

In the ALLPATHS it is advice to use a **reference genome** if one is available to help building the genome: using *X.tropicalis*.
DATA directories = sets of reads to assemble.
Arguments to give 

> PRE – the root directory in which the ALLPATHS pipeline directory will be created. (= '/work/ben/Mellotropicalis_corrected_data')

> REFERENCE_NAME – the REFERENCE (organism) directory name 

> DATA_SUBDIR – the DATA (project) directory name

> RUN – the RUN (assembly pre ‐ processing) directory name (='allpaths')

> SUBDIR – the SUBDIR (assembly) directory name

#### Preparing the data
We have paired-end libraries. We need to rename the files `Ben_Evans_BJE3652_180_BP_Library_2nd_Sequence_09082015_NoIndex_L008_R1_011_trim_paired.fastq.gz` needs to become `Ben_Evans_BJE3652_180_BP_Library_2nd_Sequence_09082015_NoIndex_L008_R1_011_trim_paired.A.fastq.gz` .
```bash
#!/bin/bash

#for file in *R1*.fastq.gz; do
#    mv "$file" "${file/.fastq.gz/.A.fastq.gz}"
#done

#for file2 in *R2*.fastq.gz; do
#    mv "$file2" "${file2/.fastq.gz/.B.fastq.gz}"
#done

for file in *R1*.fastq.gz; do
    mv "$file" "${file/_R1/}"
done

for file2 in *R2*.fastq.gz; do
    mv "$file2" "${file2/_R2/}"
done
```
```
(on scratch)
module load allpathslg
PrepareAllPathsInputs.pl DATA_DIR=/scratch/ben/allpath_assembly/X_mellotropicalis/data PLOIDY=2 IN_GROUPS_CSV=/scratch/ben/allpath_assembly/X_mellotropicalis/in_groups.csv IN_LIBS_CSV=/scratch/ben/allpath_assembly/X_mellotropicalis/in_libs.csv 
```
`PLOIDY` only 1 (haploid) or 2 (diploid) no other ploidy level tested.
The `DATA_DIR` needs to contain the `in_groups.csv` & `in_libs.csv` files.
The reference genome must be supplied as two files: genome.fasta and genome.fastb. (Run `Fasta2Fastb`) - 1st we will do it without any ref. seq (`Run1`).

`in_groups.csv`
```
group_name,library_name,file_name
6kb,Illumina_6kb,/scratch/ben/allpath_assembly/X_mellotropicalis/data/Ben-Evans-BJE3652-6kb_NoIndex_*.fastq.gz
1kb,Illumina_1kb,/scratch/ben/allpath_assembly/X_mellotropicalis/data/BenEvansBJE3652_1000bp_Library*.fastq.gz
10kb,Illumina_10kb,/scratch/ben/allpath_assembly/X_mellotropicalis/data/Ben_Evans_BJE3652_10kb_Mate_Pair_Library*.fastq.gz
180bp_2,Illumina_180bp_2,/scratch/ben/allpath_assembly/X_mellotropicalis/data/Ben_Evans_BJE3652_180_BP_Library_2nd_Sequence*.fastq.gz
180bp_1,Illumina_180bp,/scratch/ben/allpath_assembly/X_mellotropicalis/data/BenEvansBJE3652_180bp_Library_GTTTCG*.fastq.gz
400bp,Illumina_400bp,/scratch/ben/allpath_assembly/X_mellotropicalis/data/BenEvansBJE3652_400bp*.fastq.gz
6kb_2,Illumina_6kb_2,/scratch/ben/allpath_assembly/X_mellotropicalis/data/Ben_Evans_BJE3652_6kb_2nd_Sequencing*.fastq.gz
```
We need to have a separate group for each pair of reads:
```perl
#!/usr/bin/perl

# This script is to produce the input file
# for allpaths: "in_groups.csv" 

use strict;
use warnings;
my @files;
my @files_R1_180_1;
my @files_R1_180_2;
my @files_R1_400;
my @files_R1_1000;
my @files_R1_6000_1;
my @files_R1_6000_2;
my @files_R1_10000;
my $path_to_data;
my $output = "in_groups.csv";

# Use the open() function to create the file.
unless(open FILE, '>'.$output) {
    # Die with error message 
    # if we can't open it.
    die "\nUnable to create $output\n";
}

$path_to_data = "/scratch/ben/allpath_assembly/X_mellotropicalis/data/";
print FILE "group_name,library_name,file_name","\n";

##1st library
#180bp_1,Illumina_180bp,/scratch/ben/allpath_assembly/X_mellotropicalis/data/BenEvansBJE3652_180bp_Library_GTTTCG*.fastq.gz

@files_R1_180_1 = glob($path_to_data."BenEvansBJE3652_180bp_Library_GTTTCG*A.fastq.gz");
my $y;
for ($y=0; $y<=$#files_R1_180_1; $y ++) {
    print FILE "180bp_1_",$y,",Illumina_180bp,", $files_R1_180_1[$y],"\n";
}

##2nd library
#180bp_2,Illumina_180bp_2,/scratch/ben/allpath_assembly/X_mellotropicalis/data/Ben_Evans_BJE3652_180_BP_Library_2nd_Sequence*.fastq.gz

@files_R1_180_2 = glob($path_to_data."Ben_Evans_BJE3652_180_BP_Library_2nd_Sequence*A.fastq.gz");
for ($y=0; $y<=$#files_R1_180_2; $y ++) {
    print FILE "180bp_2_",$y,",Illumina_180bp_2,", $files_R1_180_2[$y],"\n";
}

##3rd library
#400bp,Illumina_400bp,/scratch/ben/allpath_assembly/X_mellotropicalis/data/BenEvansBJE3652_400bp*.fastq.gz

@files_R1_400 = glob($path_to_data."BenEvansBJE3652_400bp*A.fastq.gz");
for ($y=0; $y<=$#files_R1_400; $y ++) {
    print FILE "400bp_",$y,",Illumina_400bp,", $files_R1_400[$y],"\n";
}

##4th library
#1kb,Illumina_1kb,/scratch/ben/allpath_assembly/X_mellotropicalis/data/BenEvansBJE3652_1000bp_Library*.fastq.gz

@files_R1_1000 = glob($path_to_data."BenEvansBJE3652_1000bp_Library*A.fastq.gz");
for ($y=0; $y<=$#files_R1_1000; $y ++) {
    print FILE "1kb_",$y,",Illumina_1kb,", $files_R1_1000[$y],"\n";
}

##5th library
#6kb,Illumina_6kb,/scratch/ben/allpath_assembly/X_mellotropicalis/data/Ben-Evans-BJE3652-6kb_NoIndex_*.fastq.gz

@files_R1_6000_1 = glob($path_to_data."Ben-Evans-BJE3652-6kb_NoIndex_*A.fastq.gz");
for ($y=0; $y<=$#files_R1_6000_1; $y ++) {
    print FILE "6kb_1",$y,",Illumina_6kb,", $files_R1_6000_1[$y],"\n";
}

##6th library
#6kb_2,Illumina_6kb_2,/scratch/ben/allpath_assembly/X_mellotropicalis/data/Ben_Evans_BJE3652_6kb_2nd_Sequencing*.fastq.gz

@files_R1_6000_2 = glob($path_to_data."Ben_Evans_BJE3652_6kb_2nd_Sequencing*A.fastq.gz");
for ($y=0; $y<=$#files_R1_6000_2; $y ++) {
    print FILE "6kb_2_",$y,",Illumina_6kb_2,", $files_R1_6000_2[$y],"\n";
}

##7th library
#10kb,Illumina_10kb,/scratch/ben/allpath_assembly/X_mellotropicalis/data/Ben_Evans_BJE3652_10kb_Mate_Pair_Library*.fastq.gz
@files_R1_10000 = glob($path_to_data."Ben_Evans_BJE3652_10kb_Mate_Pair_Library*A.fastq.gz");
for ($y=0; $y<=$#files_R1_10000; $y ++) {
    print FILE "10kb_",$y,",Illumina_10kb,", $files_R1_10000[$y],"\n";
}

#Change the "A" into "*"
# close the file.
close FILE;

my $commandline;
my $status;
$commandline = "sed -i -e s/A.fastq.gz/\*.fastq.gz/g ".$output;
print $commandline;
$status=system($commandline);

exit 0;
```

`in_libs.csv`
```
library_name,project_name,organism_name,type,paired,frag_size,frag_stddev,insert_size,insert_stddev,read_orientation,genomic_start,genomic_end
Illumina_180bp,Mellotropicalis_poject,Xenopus_mellotropicalis,fragment,1,90,60,,,inward,0,0
Illumina_180bp_2,Mellotropicalis_poject,Xenopus_mellotropicalis,fragment,1,90,60,,,inward,0,0
Illumina_400bp,Mellotropicalis_poject,Xenopus_mellotropicalis,fragment,1,90,60,,,inward,0,0
Illumina_1kb,Mellotropicalis_poject,Xenopus_mellotropicalis,fragment,1,90,60,,,inward,0,0
Illumina_6kb,Mellotropicalis_poject,Xenopus_mellotropicalis,jumping,1,,,6000,500,outward,0,0
Illumina_6kb_2,Mellotropicalis_poject,Xenopus_mellotropicalis,jumping,1,,,6000,500,outward,0,0
Illumina_10kb,Mellotropicalis_poject,Xenopus_mellotropicalis,jumping,1,,,10000,500,outward,0,0
```
Some issues with the memory. 

From one of the `.log` file:
```
Sun Nov 20 13:16:05 2016 (MPF): Merging.

Fatal error (pid=19712) at Sun Nov 20 13:24:38 2016:
Attempt to write 16384 bytes to /scratch/ben/allpath_assembly/X_mellotropicalis/data/read_cache/180b
p_1_0.tmp/all.qualb failed after writing 0 bytes: No space left on device [errno=28].


Sun Nov 20 13:24:38 2016.  Abort.  Stopping.

Generating a backtrace...

Dump of stack:

0. CRD::exit(int), in ??:0
1. FileWriter::write(void const*, unsigned long) const, in FileWriter.cc:53
2. writeBuf, in BinaryStream.h:158
3. writeArray<long unsigned int>, in BinaryStream.h:135
4. write<long unsigned int>, in BinaryStream.h:84
5. FeudalFileWriter::close(), in FeudalFileWriter.cc:78
```

Try again with deleting all the intermediate files from previous attempts (in case some of them weren't overwritten). If still issues see what we can do with some options that don't appear in the Manual:
```
Nov 21 08:35:17 2016 run on localhost (pid=25439), last modified Nov 17 15:29:25 2016
/opt/sharcnet/allpathslg/52488/bin/ConvertToFastbQualb.pl                      \
    PICARD_TOOLS_DIR=                                                          \
    TMP_DIR=/scratch/ben/allpath_assembly/X_mellotropicalis/data/read_cache/picard_tmp \
    DATA_FILE=/scratch/ben/allpath_assembly/X_mellotropicalis/data/BenEvansBJE3652_180bp_Library_GTTTCG_L001_004_trim_paired.cor.*.fastq.gz \
    PAIRED=1                                                                   \
    OUT_HEAD=/scratch/ben/allpath_assembly/X_mellotropicalis/data/read_cache/180bp_1_3 \
    REVERSE_READS=False TRIM_START=0 TRIM_END=0 INCLUDE_NON_PF_READS=1         \
    PHRED_64=0 FORCE_PHRED=0 REVERT_SAM=0 OVERWRITE=0 SAVE_COMPRESSED_FASTQ=0  \
    SAVE_INTERMEDIATES=0 JAVA_MEM_GB=8 DRY_RUN=0 VERBOSE=1
```
From the [Allpaths website](http://software.broadinstitute.org/allpaths-lg/blog/?page_id=215):

*C2. How much memory does ALLPATHS-LG require?*

*Peak usage is roughly 1.7 bytes per read base, at least for mammalian-size genomes. If you find that memory usage is much higher than this, we will try to help.  There are many places in the algorithm where memory usage could be reduced.*

Potential memory issues considering the number of intermediate and "final" files produced even when just running the assembly on the test data -> a looooot of files will be created in new directories also created by the program. No information if they are necessary for running or just for recovery, if memory issues, try moving intermediate files produced by the 1st command to freezer and then run the assembly.

On a [discussion website](https://www.biostars.org/p/8973/), John St John (crocodilian assembly):

*The broad talks about some genomes >500MB it assembled posted on its allpaths-lg blog. I personally haven't had luck with it yet b/c not all of the modules respect the MAX_MEM_GB (or something similar) argument. I have a 1TB system to work on, but it is shared, so it crashes at one of the modules that looks at how much memory is available and tries to use it all. If you are on your own dedicated system with enough ram then you should be ok. They claim to be fixing that particular issue now so people on shared systems can use the program.*

*I used Allpaths LG to generate the preliminary assemblies in the Crocodilian genome announcement paper last year http://genomebiology.com/content/13/1/415. Using a combination overlap library, and a reasonable coverage 2kb insert library using a custom protocol that Nader Pourmand at UCSC developed, we were able to achieve a scaffold N50 of 106Kb, and a contig N50 of 28Kb. I have not been involved with the project recently, so I am not sure what the current state of the assemblies are, but Allpaths-LG did do a good job on that genome with the data we had available at the time.* 

It was ~5years ago but it seems to still be the case.

Try the permanent cache?
```
  CacheLibs.pl 
    CACHE_DIR=<CACHE_DIR> 
    IN_LIBS_CSV=in_libs.csv  
    ACTION=Add 
  CacheGroups.pl 
    CACHE_DIR=<CACHE_DIR> 
    PICARD_TOOLS_DIR=/opt/picard/bin  
    IN_GROUPS_CSV=in_groups.csv  
    TMP_DIR=/large-tmp 
    HOSTS=’2,3.host2,4.host3’ 
    ACTION=Add 
```
Try what the crocodile guy tried (even if it wasn't workin, maybe since then it has been fixed):
```
PrepareAllPathsInputs.pl DATA_DIR=/scratch/ben/allpath_assembly/X_mellotropicalis/data PLOIDY=2 IN_GROUPS_CSV=/scratch/ben/allpath_assembly/X_mellotropicalis/in_groups.csv IN_LIBS_CSV=/scratch/ben/allpath_assembly/X_mellotropicalis/in_libs.csv HOSTS=8 MAX_MEM_GB=400 
```
By specifying `MAX_MEM_GB=500` when re-running (no overwrite): new files (that previously failed) were created (ex. `6kb_2_2.fastb`) (was OK because some nodes with a lot of memory and nobody was running but when someone: crashed). Run on Iqaluk (before Wobbie) for the last files `6kb_10` to `6kb_19` without memory restriction. (Failed when used small values)

Looking on the internet, a lot of memory issues for people using this software for big genome:
[Here](http://seqanswers.com/forums/showthread.php?t=45543) - problem for a mouse genome running on a server -> ask sharcnet which node to select, only run on this one and alocating a lot (>500Gb) of memory? (no multi-threads?) 

Another one [here](http://seqanswers.com/forums/showthread.php?t=25729):
*After some profiling by using the collectl, I found that the last program running before my allpaths-lg job terminated is FindErrors. And the reason was FindErrors tried to allocate more memory than it is available on the machine for loading some files. So I reran my job on another machine that has 2TB memory and it worked. Hope this will help.*

Sounds like we will need help from Mark (sharcnet) and/or Brian... Interesting software that asks you to have a lot of data to have a lot of coverage with different insert size (minimum being one small and one big >2kb) but requires too much memory. Not sure how much we will need for this tetraploid genome and all the data we have (needed to try to solve the main issues of tetraploid genome: high heterozigosity & repeat elements)... And for the moment it is the 1st step, preparing the data.
We will probably needs the help from the software team who was very helpful for the crocodile genome. Memory issues were also reported [there](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4173024/) when they tried to incorporate PacBio sequences.

#### Solution
We previously wanted to use `/scratch` since there is no limit of space but almost full.... So come back on `/work` but need to check regularly if we are overquota. Need to either delete directly the apparently not necessary outputs of the 1st step or `mv` them to freezer until the complete assembly is done (max 1 month?) just in case. Run on `wobbie` (`wob101`) to have enough RAM. Not too many threats to not have competition for memory.
```
PrepareAllPathsInputs.pl DATA_DIR=/work/ben/Mellotropicalis_corrected_data/allpaths/data PLOIDY=2 IN_GROUPS_CSV=/work/ben/Mellotropicalis_corrected_data/allpaths/in_groups.csv IN_LIBS_CSV=/work/ben/Mellotropicalis_corrected_data/allpaths/in_libs.csv HOSTS=8 MAX_MEM_GB=400
```
Other issues: fragment files not created because `GROUP_READ_SIZES (vec<double>)` not specified. No explanation what it is in the manual. Because at the beginning we only need to give 2 files, the issue should come from one of them. Some people have noticed a bad conversion with excel to `.csv` with blank not having single space. When we run again still same error. So delete the previous files and run again. Only issue with the fragment part, no problem with the jumping libraries.

##### Try subsetting (see if memory issue)
- When runnning on only 1 couple of files (1 R1, 1 R2) for each library:`PrepareAllPathsInputs.pl` runs perfectly.
- When running on everything except the 2nd sequencing of 180pb: worked!
- Everything + half the 2nd sequencing of 180pb: not working
- Everything + 1/3 the 2nd sequencing of 180pb: not working
- Everything + 1/4 the 2nd sequencing of 180pb: not working
- Everything + 1/5 the 2nd sequencing of 180pb: not working
- Everything + 1/10 the 2nd sequencing of 180pb: not working (try without parallelization, and allowing more memory `500G` still not working even when don't specify the memory limit)
- Everything + 2 couples of the 2nd sequencing of 180pb: worked

Ok so it is definitely a memory issue. Let's go whithout the 180pb-2nd sequencing libraries and try the 2nd step (the assembly) to see if we will have a memory issue after.
```
PrepareAllPathsInputs.pl DATA_DIR=/work/ben/Mellotropicalis_corrected_data/allpaths/data PLOIDY=2 IN_GROUPS_CSV=/work/ben/Mellotropicalis_corrected_data/allpaths/in_groups_test_no_180_2.csv IN_LIBS_CSV=/work/ben/Mellotropicalis_corrected_data/allpaths/in_libs.csv HOSTS=8 MAX_MEM_GB=400
RunAllPathsLG PRE=/work/ben/Mellotropicalis_corrected_data REFERENCE_NAME=allpaths DATA_SUBDIR=data RUN=Run1_no_180_2 TARGETS=standard THREADS=8 
```
```
Giving up.  Here are some possible solutions:
- Run without other competing processes (if that's the problem).
- Run on a server having more memory, or reduce your input data amount.
- Consider using the MAX_MEM_GB or MEMORY_CHECK options (if available).
```
`You should not have specified a value for MAX_MEM_GB` for any value tried. Try with no limit, no threat.
```
Dang dang dang, we've got a problem.
Attempt to allocate memory failed, memory usage before call = 24.73 GB.
--------------------------------------------------------------------------------
Top memory processes on this server now:
  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
 8302 ben       20   0 29.6g  24g 1628 S  0.0 78.5   6:27.87 RemoveDodgyRead
 8202 ben       20   0  118m 6724 1880 S  0.0  0.0   0:00.11 exe
 8305 ben       20   0 23092 5912 1440 S  0.0  0.0   0:02.14 MemMonitor
 2483 nobody    20   0  183m 4512 2012 S  0.0  0.0  51:06.55 gmond
 2225 nslcd     20   0  433m 3516 1116 S  0.0  0.0   0:00.41 nslcd
--------------------------------------------------------------------------------
Stack trace (sometimes informative):
0. our_new_handler(), in RunTime.cc:586
1. OuterVec<SerfVec<unsigned char>, MempoolOwner<unsigned char>, allocator<SerfVec<unsigned char> > >::realloc(...), in new_allocator.h:104
2. reserve, in OuterVec.h:219
3. resize, in OuterVec.h:196
4. appendFromFeudal, in MasterVec.h:307
--------------------------------------------------------------------------------
Giving up.  Here are some possible solutions:
- Run without other competing processes (if that's the problem).
- Run on a server having more memory, or reduce your input data amount.
- Consider using the MAX_MEM_GB or MEMORY_CHECK options (if available).

make: *** [/work/ben/Mellotropicalis_corrected_data/allpaths/data/Run1_no_180_2/frag_reads_filt.fastb] Error 1

Sat Nov 26 17:00:39 2016 : make process finished.

Sat Nov 26 17:00:40 2016: Computing runtime statistics.

 e_time(sec)  u_time(sec)  vmrss(MB)  vmsize(MB)   module name 
--------------------------------------------------------------------------------
       41720          101      15845       17716   ValidateAllPathsInputs
       10697          286      26561       32008   RemoveDodgyReads
--------------------------------------------------------------------------------
       52418          388      26561       32008   Total/Peak 2 modules

Sat Nov 26 17:00:41 2016: Compiling assembly report.

------------------ Memory and CPU usage

             32    available cpus
           31.5    GB of total available memory
       144845.5    GB of available disk space
          12.43    hours of total elapsed time
          14.56    hours of total per-module elapsed time
           0.11    hours of total per-module user time
           0.01    effective parallelization factor
          25.94    GB memory usage peak



Sat Nov 26 17:00:42 2016 : ALLPATHS-LG Pipeline Finished.

Run directory: /work/ben/Mellotropicalis_corrected_data/allpaths/data/Run1_no_180_2
Log directory: /work/ben/Mellotropicalis_corrected_data/allpaths/make_log/data/Run1_no_180_2/test/2016-11-26T14:02:17

 *** Make encountered an error, see above for error messages. ***
```
Ben's suggestion of increasing the number of threats (`THREADS=20`) also failed with the same error message about the memory.
#### Running the assembly
```
RunAllPathsLG
PRE=/work/ben/Mellotropicalis_corrected_data
REFERENCE_NAME=allpaths
DATA_SUBDIR=data
RUN=Run1
TARGETS=standard
#EVALUATION=standard #not for Run1 (don't use X. tropicalis as a reference)
THREADS=10
```
!!!! Differences with Abyss & SOAPdenovo: no need of specify a k-mer size (default `K=96`). No direct linked between k-mer size and read length. Allpaths uses multiple values when building the assembly. 

On iqaluk
```
Tue Nov 29 13:37:13 2016 (FE): Analysing kmer spectrum.
Tue Nov 29 13:37:13 2016 (KS): Writing kmer spectrum to '/work/ben/Mellotropicalis_corrected_data/allpaths/data/Run1_no_180_2/frag_reads_filt.25mer.kspec'.
Tue Nov 29 13:37:14 2016 (KSC): Estimating genome size.
Tue Nov 29 13:37:15 2016 (KSC): ------------------- Kmer Spectrum Analysis -------------------
Tue Nov 29 13:37:15 2016 (KSC): Genome size estimate        =  2,769,508,532 bases
Tue Nov 29 13:37:15 2016 (KSC): Genome size estimate CN = 1 =  1,415,582,158 bases (  51.1 % )
Tue Nov 29 13:37:15 2016 (KSC): Genome size estimate CN > 1 =  1,353,926,374 bases (  48.9 % )
Tue Nov 29 13:37:15 2016 (KSC): Coverage estimate           =             16 x
Tue Nov 29 13:37:15 2016 (KSC): Bias stddev at scale > K    =           0.18
Tue Nov 29 13:37:15 2016 (KSC): Base error rate estimate    =         0.0001 (Q = 41.5)
Tue Nov 29 13:37:15 2016 (KSC): SNP rate: always verify with kmer spectrum plot.
Tue Nov 29 13:37:15 2016 (KSC): Ploidy                      =              2
Tue Nov 29 13:37:15 2016 (KSC): SNP rate                   ~=          1/211
Tue Nov 29 13:37:15 2016 (KSC): SNPs closer than K         ~=             21 %
Tue Nov 29 13:37:15 2016 (KSC): --------------------------------------------------------------
PERFSTAT: estimated genome size in bases [genome_size_est] = 2769508532
PERFSTAT: % genome estimated to be repetitive (at K=25 scale) [genome_repetitiveness_est] = 48.0
PERFSTAT: estimated genome coverage by fragment reads [genome_cov_est] = 16
PERFSTAT: estimated standard deviation of sequencing bias (at K=25 scale) [bias_stddev_est] = 0.18
Tue Nov 29 13:37:15 2016 (FE): Reading quals as nibble from '/work/ben/Mellotropicalis_corrected_data/allpaths/data/Run1_no_180_2/frag_reads_filt.qualb'.
Tue Nov 29 13:52:25 2016 (FEC): cycle = 0/2
Tue Nov 29 13:52:25 2016 (FEC): Renormalizing quality scores.
Tue Nov 29 13:55:25 2016 (FEC): Duplicating 'bases' into 'bases_new'.
Tue Nov 29 13:56:25 2016 (FEC): Mimicking 'bases' into 'base_locked'.
Tue Nov 29 13:57:09 2016 (FEC): Gathering list of base-locations to correct.
Tue Nov 29 13:57:15 2016 (NK): Starting kmerization.
Tue Nov 29 13:57:30 2016 (NK):   n_threads     =                  8
Tue Nov 29 13:57:30 2016 (NK):   K             =                 24
Tue Nov 29 13:57:30 2016 (NK):   sizeof_krec   =                 16
Tue Nov 29 13:57:30 2016 (NK):   n_bv          =        626,938,038
Tue Nov 29 13:57:30 2016 (NK):   n_kmers       =     47,334,454,754
Tue Nov 29 13:57:30 2016 (NK):   mem_total     =  1,084,165,799,936
Tue Nov 29 13:57:30 2016 (NK):   mem_used      =    111,151,308,800
Tue Nov 29 13:57:30 2016 (NK):   mem_avail     =    973,014,491,136
Tue Nov 29 13:57:30 2016 (NK):   mem_mean      =    243,253,622,784
Tue Nov 29 13:57:30 2016 (NK):   mem_mean_user =                  0
Tue Nov 29 13:57:30 2016 (NK):   mem_needed    =  1,514,702,552,128
Tue Nov 29 13:57:30 2016 (NK):   mem_to_use    =    151,470,255,212
Tue Nov 29 13:57:30 2016 (NK):   n_parcels     =                 80
Tue Nov 29 13:57:30 2016 (NK):   n_passes      =                 10
```
Estimated genome size slightly smaller (~2.8 x 10^9) than X. laevis (3.1 x 10^9 bp), and less than 2 times the genome of X. tropicalis (1.7 x 10^9 bp). The repetitive portion of the genome seems to be high (48%) but makes sense (repeat sequences + duplicated genome).
```
Wed Nov 30 15:59:06 2016 (CCR): Loading pairing info from '/work/ben/Mellotropicalis_corrected_data/allpaths/data/Run1_no_180_2/frag_reads_edit.pairs'.
Wed Nov 30 16:00:45 2016 (CCR): Loaded 313469019 pairs.
Wed Nov 30 16:00:45 2016 (CCR): Removing unique reads.

Wed Nov 30 16:01:17 2016 (CCR): REPORT
Wed Nov 30 16:01:17 2016 (CCR):    626,938,038 (100.0 %)  reads in.
Wed Nov 30 16:01:17 2016 (CCR):    626,938,038 (100.0 %)  paired reads in.
Wed Nov 30 16:01:17 2016 (CCR):              0 (  0.0 %)  unpaired reads in.
Wed Nov 30 16:01:17 2016 (CCR):
Wed Nov 30 16:01:17 2016 (CCR):    619,750,111 ( 98.9 %)  reads out.
Wed Nov 30 16:01:17 2016 (CCR):    612,943,910 ( 97.8 %)  paired reads out.
Wed Nov 30 16:01:17 2016 (CCR):      6,806,201 (  1.1 %)  unpaired reads out.
Wed Nov 30 16:01:17 2016 (CCR):      6,806,201 (  1.1 %)  unpaired reads gained from broken pairs.
Wed Nov 30 16:01:17 2016 (CCR):
Wed Nov 30 16:01:17 2016 (CCR):      7,187,927 (  1.1 %)  reads removed.
Wed Nov 30 16:01:17 2016 (CCR):        381,726 (  0.1 %)  A and B reads removed.
Wed Nov 30 16:01:17 2016 (CCR):      3,408,346 (  0.5 %)  A reads removed where B read is kept.
Wed Nov 30 16:01:17 2016 (CCR):      3,397,855 (  0.5 %)  B reads removed where A read is kept.
Wed Nov 30 16:01:17 2016 (CCR):              0 (  0.0 %)  unpaired reads removed.
PERFSTAT: % of reads removed because of low frequency kmers [frac_reads_removed] = 1.1
Wed Nov 30 16:01:17 2016 (CCR): Writing output files.
Wed Nov 30 16:01:17 2016 (CCR): Writing bases to '/work/ben/Mellotropicalis_corrected_data/allpaths/data/Run1_no_180_2/frag_reads_corr.fastb'.
```
Cool only ~1% of reads (previously corrected by Trimmomatic + Quake) considered as bad and removed by the assembler.
```
Thu Dec 01 13:34:25 2016 Filled 45.8873% of 306471955 pairs.
lib_name        lib_ID  sep  dev  n_reads
--------        ------  ---  ---  -------
Illumina_180bp       0   11   20  298587636
Illumina_1kb         1  751  100  9070418
Illumina_400bp       2  174   40  305285856
Unpaired             -    -    -  6806201

PERFSTAT: % of fragment pairs that were filled [frac_filled_pairs] = 45.9
```
```
Fri Dec 02 09:49:32 2016: Original Stats:
lib_name        lib_ID  sep  dev  n_reads
--------        ------  ---  ---  -------
Illumina_180bp       0  -16   20  305447912
Illumina_1kb         1  806  100  9306348
Illumina_400bp       2  204   40  312183778

Fri Dec 02 09:49:32 2016: Replacement Stats:
lib_name        lib_ID  sep  dev  n_reads
--------        ------  ---  ---  -------
Illumina_180bp       0   11   20  305447912
Illumina_1kb         1  751  100  9306348
Illumina_400bp       2  174   40  312183778
```
#### Comments
Thanks to Mark (sharcnet), the assembly is running well. It uses a lot of memory (RAM, virtual and outputs), it was needed to increase the memory that we can use on Iqaluk (peak of memory usage > 550 Gb). When the assembly, which for the moment uses all the data except the library `180pb-2nd sequencing`, is done, we will try to run it again using all the data (if the statistics are better than the SOAPdenovo assembly). Before running again, keep `.fa` and the stats files in a safe place.

Needed to restart it when sharcnet had maintenance work.
```
RunAllPathsLG PRE=/work/ben/Mellotropicalis_corrected_data REFERENCE_NAME=allpaths DATA_SUBDIR=data RUN=Run1_no_180_2 THREADS=1 OVERWRITE=True
```
The run didn't start again where it stopped (~2/3weeks lost). 
#### Results
##### Statistics report
```
less /4/evanslab/Mellotropicalis_2016/assembly_stats.report


--------------------------------------------------------------------------------
Tue Jan 31 11:49:09 2017 run on iqaluk, pid=13814 [Nov 15 2016 19:39:43 R52488 ]
AllPathsReport PRE=/work/ben/Mellotropicalis_corrected_data                    \
               DATA=allpaths/data RUN=Run1_no_180_2 SUBDIR=test                \
               ASSEMBLY=final MM=True _MM_INTERVAL=10 _MM_SUMMARY=False        \
               _MM_OUT=/work/ben/Mellotropicalis_corrected_data/allpaths/data/ \
               Run1_no_180_2/ASSEMBLIES/test/makeinfo/assembly_stats.report.mm \
               .AllPathsReport
--------------------------------------------------------------------------------


Redirecting standard output to the following files:
/work/ben/Mellotropicalis_corrected_data/allpaths/data/Run1_no_180_2/ASSEMBLIES/test/assembly_stats.report
/work/ben/Mellotropicalis_corrected_data/allpaths/data/Run1_no_180_2/ASSEMBLIES/test/makeinfo/assembly_stats.report.out.AllPathsReport
/work/ben/Mellotropicalis_corrected_data/allpaths/make_log/data/Run1_no_180_2/test/2017-01-09T15:56:13/AllPathsReport.out

PERFSTAT: contig minimum size for reporting [ap_report_min_contig] = 1000
PERFSTAT: number of contigs [n_contigs] = 335094
PERFSTAT: number of contigs per Mb [contigs_per_Mb] = 591.1
PERFSTAT: number of scaffolds [n_scaffolds] = 320227
PERFSTAT: total contig length [contig_length] = 530543843
PERFSTAT: total scaffold length, with gaps [scaff_length_gap] = 566922312
PERFSTAT: N50 contig size in kb [N50_contig] = 1.6
PERFSTAT: N50 scaffold size in kb [N50_scaffold] = 2
PERFSTAT: N50 scaffold size in kb, with gaps [N50_scaff_gap] = 2
PERFSTAT: number of scaffolds per Mb [scaff_per_Mb] = 564.85
PERFSTAT: median size of gaps in scaffolds [median_gap] = -754
PERFSTAT: median dev of gaps in scaffolds [median_gap_dev] = 331
PERFSTAT: % of bases in captured gaps [frac_captured_gaps] = 6.94
PERFSTAT: % of bases in negative gaps (after 5 devs) [frac_negative_gaps] = 3.45
PERFSTAT: %% of ambiguous bases [amb_base_frac] = 202.94
PERFSTAT: ambiguities per 10,000 bases [ambiguity_frac] = 14.49
```
Globally doesn't seem to be better than the previous SOAPdenovo assembly.

##### Library coverage
```
less /work/ben/Mellotropicalis_corrected_data/allpaths/data/Run1_no_180_2/ASSEMBLIES/test/library_coverage.report

--------------------------------------------------------------------------------
Tue Jan 31 13:16:19 2017 run on iqaluk, pid=39961 [Nov 15 2016 19:39:43 R52488 ]
LibCoverage PRE=/work/ben/Mellotropicalis_corrected_data DATA=allpaths/data    \
            RUN=Run1_no_180_2 SUBDIR=test                                      \
            ASSEMBLY=linear_scaffolds0.clean.remodel.applied.tag.fixed         \
            NUM_THREADS=1 MM=True _MM_INTERVAL=10 _MM_SUMMARY=False            \
            _MM_OUT=/work/ben/Mellotropicalis_corrected_data/allpaths/data/Run \
            1_no_180_2/ASSEMBLIES/test/makeinfo/library_coverage.report.mm.Lib \
            Coverage
--------------------------------------------------------------------------------


Redirecting standard output to the following files:
/work/ben/Mellotropicalis_corrected_data/allpaths/data/Run1_no_180_2/ASSEMBLIES/test/library_coverage.report
/work/ben/Mellotropicalis_corrected_data/allpaths/data/Run1_no_180_2/ASSEMBLIES/test/makeinfo/library_coverage.report.out.LibCoverage
/work/ben/Mellotropicalis_corrected_data/allpaths/make_log/data/Run1_no_180_2/test/2017-01-09T15:56:13/LibCoverage.out

Unable to find pairs file: /work/ben/Mellotropicalis_corrected_data/allpaths/data/Run1_no_180_2/long_jump_reads_filt.pairs
Tue Jan 31 13:16:51 2017: loading pairing info for frag
Tue Jan 31 13:20:01 2017: loading pairing info for jump
Tue Jan 31 13:20:47 2017: found 6 libraries
Tue Jan 31 13:20:47 2017: computing physical coverage
Tue Jan 31 13:30:32 2017: counting reads in input
Tue Jan 31 13:38:21 2017: generating output table
PERFSTAT: BLOCK_START [LibCoverage table]

LEGEND
   n_reads:  number of reads in input
   %_used:   % of reads assembled
   scov:     sequence coverage
   n_pairs:  number of valid pairs assembled
   pcov:     physical coverage

type  lib_name          lib_stats      n_reads  %_used  scov     n_pairs  pcov
                                                                              
frag  Illumina_180bp    11 +/- 20  305,450,552    58.7  31.3  53,383,482  17.8
frag  Illumina_1kb    751 +/- 100    9,306,400    56.4   0.9     531,922   1.4
frag  Illumina_400bp   174 +/- 40  312,185,354    56.9  30.9  37,197,733  28.2
frag  === total ===                626,942,306    57.8  63.1  91,113,137  47.3
                                                                              
jump  Illumina_10kb   537 +/- 450  230,754,144     3.4   1.4     856,268   0.5
jump  Illumina_6kb    595 +/- 574  215,298,464     0.3   0.2     152,486   0.2
jump  Illumina_6kb_2  595 +/- 564  201,445,974     0.4   0.1     109,389   0.2
jump  === total ===                647,498,582     1.4   1.7   1,118,143   0.9
                                                                              
PERFSTAT: BLOCK_STOP
Tue Jan 31 13:38:21 2017: done
```
### Assembly reconciliation?
Each assembler has has their own advantages and desavantages producing different types of errors in the assembly. The idea will be to use the 2 assemblies produced by SOAPdenovo and Allpaths using the data except the library `180bp_2nd_sequencing`.
[GAM-NGS](https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-14-S7-S6) might be interesting to look at but requires to map the reads back against to each assembly (SAM files)...

##On test data
```
module load allpathslg
PrepareAllPathsInputs.pl DATA_DIR=/scratch/ben/allpath_assembly/ALLPATHS-LG.test_genome/seq IN_GROUPS_CSV=/scratch/ben/allpath_assembly/ALLPATHS-LG.test_genome/seq/in_groups.csv IN_LIBS_CSV=/scratch/ben/allpath_assembly/ALLPATHS-LG.test_genome/seq/in_libs.csv
RunAllPathsLG PRE=/scratch/ben/allpath_assembly/ REFERENCE_NAME=ALLPATHS-LG.test_genome DATA_SUBDIR=seq RUN=myrun TARGETS=standard 
```
Checked with test files if really no overwritting of the files that were successfully produced (`.qualb` `.fastb`) in `read_cache`: no but produced new final files in the `seq` directory. -> so try to run multiple times for our data and see if we can produce the needed files for the ones that we previously couldn't. (no `overwrite` information of this step in the manual).

(`myrun` is created while running, needs a `ploidy` file in the DATA directory)

## Hybrid assembly

We should have also in the future some PacBio sequences. The advantage of Pacbio is that it is long reads but with a lot of errors. They can be use to improve a draft assembly previously made using Illumina libraries (see for example [Olsen et al. 2015](https://gigascience.biomedcentral.com/articles/10.1186/s13742-015-0094-1)). [DBG2OLC](http://www.nature.com/articles/srep31900) seems to be an interesting option since it was tested on big genomes such as human.
From the [github page](https://github.com/yechengxi/DBG2OLC/):

*Step1. Use an accurate DBG-assembler to construct short but accurate contigs. Please make sure they are the raw DBG contigs without using repeat resolving techniques such as gap closing or scaffolding. Otherwise you may have poor final results due to the errors introduced by the heuristics used in short read assembly pipelines.*

We are using `allpaths-LG` for assembling Illumina reads that seems to give the best result today. Other examples of hybrid and non-hybrid strategies [here](https://github.com/PacificBiosciences/Bioinformatics-Training/wiki/Large-Genome-Assembly-with-PacBio-Long-Reads). However after looking again at the different softwares, looks like most of them are for small genomes. 

[PBJelly](http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0047768) can also be an interesting solution using as input a draft geneome and uses Pacbio to fill-in gaps.

AHA and SSPACE-LongRead are known as hybrid assemblies and use PacBio data to scaffold contigs produced by Illumina reads but were designed for small genomes (bacteria). SSPACE-LongRead has been successfully used for [pineapple](https://academic.oup.com/dnaresearch/article/23/5/427/2236148/The-draft-genome-of-MD-2-pineapple-using-hybrid).

From 2 recent papers about assemblies of [apple](https://gigascience.biomedcentral.com/articles/10.1186/s13742-016-0139-0) and an herbal [plant](https://gigascience.biomedcentral.com/articles/10.1186/s13742-015-0104-3), using 1st a draft assembly from NGS reads and then use PacBio for scaffolding seems an ok strategy. DBG2OLC seems to be OK. See [here](http://www.nature.com/articles/srep41457) for another example of DBG2OLC.

ALLPATHS-LG can also be run with pacbio but considering all the memory issue, it is not a good idea and also was only tested for small bacteria genomes (as SSPACE for ex.).

[Utturkar et al. 2014](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4173024/): some example of de novo and hybrid softwares. From the publication, if we have a similar issue of too long sequences in one of the softwares, might need to consider a similar approach (cannot use newbler because requires pyrosequencing data) 

*The Newbler software supports fasta/fastq input along with native 454 reads. However, when quality-trimmed Illumina reads or draft assembly of Illumina reads were used as additional input, Newbler failed to complete the assembly process. This was likely because of the large size of Illumina data or long fasta sequences, respectively. Therefore, draft assemblies were cut into 1.5 kb pseudo reads with 300 bp overlap using fb_dice.pl script from the FragBlast module (http://www.clarkfrancis.com/codes/fb_dice.pl) and assembled together with native 454 reads using Newbler*
